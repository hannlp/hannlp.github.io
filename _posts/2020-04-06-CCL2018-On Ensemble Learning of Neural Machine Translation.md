---
title: CCL2018-On Ensemble Learning of Neural Machine Translation
date: 2019-04-16
tags:
- 机器翻译
- 论文阅读
---

# 1 背景
实验室李北师兄的一篇论文，针对NMT中的模型集成进行了大量的实验对比，

# 2 笔记
## 2.1 何为集成学习
是一种联合多个学习器进行协同决策的机器学习方法，通过整合多个学习器的决策结果可以有效减小预测结果的方差与偏置，显著提升模型的泛化能力，达到比单学习器更好的效果。

## 2.2 NMT中的模型集成方法
### 2.2.1 模型参数平均
即将单一模型最近保存的N个检查点的参数矩阵进行平均。

Vaswani等建议每隔10分钟保存一次模型，并平均最新保存的20个检查点。
### 2.2.2 预测结果融合
即在解码过程中，在经过Softmax得到归一化的词表上的概率分布时，整合不同模型得到的概率分布，进而预测下一个词。

由于不需要参数平均，那么模型的结构就不需要一致，这里又